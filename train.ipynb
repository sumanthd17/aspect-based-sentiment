{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO/fIvy/3egHJ8VwlmsKFiC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumanthd17/aspect-based-sentiment/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izN65hXWQD77",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a2297c1c-11cb-4899-a4cb-192059d148df"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "gpu = GPUs[0]\n",
        "\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "printm()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  | Proc size: 160.9 MB\n",
            "GPU RAM Free: 15079MB | Used: 0MB | Util   0% | Total 15079MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32dC4ovO-Hn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "7c85b3cb-b50d-4806-ab76-7c783f787689"
      },
      "source": [
        "## Install transformers library\n",
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeKHfOoA95ky",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "26d560ba-1af8-4fe7-8298-e9d82c46c13d"
      },
      "source": [
        "# Install dependencies\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import transformers as optimus"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlVxGZoLY05g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ac2b81d-fe6d-4afd-db97-f44ba3535f09"
      },
      "source": [
        "!git clone https://github.com/sumanthd17/aspect-based-sentiment.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'aspect-based-sentiment' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj-Nni9QY-1Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbcac554-dc88-4944-e74a-9f5711a0db4e"
      },
      "source": [
        "cd aspect-based-sentiment"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/aspect-based-sentiment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5GP5AnZ-O2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_train_data(input_dir):\n",
        "  \"\"\"\n",
        "  Load input train data\n",
        "\n",
        "  Arguments:\n",
        "  input_dir {str} - path to data dir\n",
        "\n",
        "  Returns:\n",
        "  df {DataFrame} - loaded data in data frame\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(input_dir + \"train-QA.csv\", sep=\"\\t\", names=['id', 'ques', 'ans', 'sentiment'])\n",
        "  return df"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7lOulxqD6PQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_val_data(input_dir):\n",
        "  \"\"\"\n",
        "  Load input test data\n",
        "\n",
        "  Arguments:\n",
        "  input_dir {str} - path to data dir\n",
        "\n",
        "  Returns:\n",
        "  df {DataFrame} - loaded data in data frame\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(input_dir + \"val-QA.csv\", sep=\"\\t\", names=['id', 'ques', 'ans', 'sentiment'])\n",
        "  return df"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9q16QCR-nFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hyper_params():\n",
        "  \"\"\"\n",
        "  Function to initialize hyper-parameters\n",
        "\n",
        "  Returns:\n",
        "  BATCH_SIZE {int} - batchsize of dataloader\n",
        "  MAX_SEQ_LENGTH {int} - maximum length of input text sequence (<512 as bert is maxed at 512)\n",
        "  LEARNING_RATE {float} - learning rate for the optimizer\n",
        "  EPOCHS {int} - total training epochs\n",
        "  WARMUP {float} - portion of warmup steps for scheduler\n",
        "  \"\"\"\n",
        "  BATCH_SIZE = 32\n",
        "  MAX_SEQ_LENGTH = 256\n",
        "  LEARNING_RATE = 2e-5\n",
        "  EPOCHS = 5\n",
        "  WARMUP = 0.1\n",
        "  return BATCH_SIZE, MAX_SEQ_LENGTH, LEARNING_RATE, WARMUP, EPOCHS"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h81rysT9-lP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# configure device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhRCLmNdYaG9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ecf07a30-3054-4cd0-8220-fbe8becb2d8a"
      },
      "source": [
        "# script for generating auxilary QA paris\n",
        "!python create_data.py"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2977\n",
            "747\n",
            "1491\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaWgHf8OY7-y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "867606a6-66ab-46d1-cfef-812d8914cf74"
      },
      "source": [
        "# load train and validation data\n",
        "train_data = load_train_data('QA_pairs/')\n",
        "val_data = load_val_data('QA_pairs/')\n",
        "\n",
        "# load hyper-parameters\n",
        "batch_size, max_seq_len, lr, warmup, epochs = hyper_params()\n",
        "\n",
        "# initialize training steps and warmup steps\n",
        "num_training_steps = int(len(train_data) / batch_size) * epochs\n",
        "num_warmup_steps = warmup * num_training_steps\n",
        "\n",
        "print(len(train_data))\n",
        "print(len(val_data))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15008\n",
            "3750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8Eu74yg49Tb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define BERT tokenizer\n",
        "# using bert-base-uncased\n",
        "tokenizer_class, pretrained_weights = (\n",
        "    optimus.BertTokenizer,\n",
        "    \"bert-base-uncased\",\n",
        ")\n",
        "\n",
        "# load the tokenizer from pre-trained model\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights, do_lower_case=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhvDpk3XDJ1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# label to index mapping\n",
        "sent2idx = {\n",
        "    'None': 0,\n",
        "    'Positive': 1,\n",
        "    'Negative': 2\n",
        "}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d89L5BtMq2_R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c3c08d01-f88b-46b2-cbd0-acea0baf9938"
      },
      "source": [
        "# visualize tokenizer output\n",
        "tokenizer('hi, my name is sumanth', 'I am an engineer')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 7632, 1010, 2026, 2171, 2003, 7680, 4630, 2232, 102, 1045, 2572, 2019, 3992, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skO5kvazcgmJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize empty dataframe\n",
        "train = pd.DataFrame()\n",
        "\n",
        "# iterate each row in previously loaded train_data\n",
        "# tokenizer(sent_a, sent_b) returns a dictionary of encoded values namely input_ids, attention_mask, token_type_ids\n",
        "# input_ids - IDs returned by bert-tokenizer\n",
        "# attention_mask - 1's for all the ids in the sentence and 0's for all padded tokens\n",
        "# token_type_ids - 0's for all tokens in sent_a, 1's for all tokens in sent_b\n",
        "for i, row in train_data.iterrows():\n",
        "  d = {}\n",
        "  encoded = tokenizer(row['ques'], row['ans'])\n",
        "  d['input_ids'] = encoded['input_ids']\n",
        "  d['attention_mask'] = encoded['attention_mask']\n",
        "  d['token_type_ids'] = encoded['token_type_ids']\n",
        "  d['label'] = sent2idx[row['sentiment']]\n",
        "  train = train.append(d, ignore_index=True)\n",
        "\n",
        "# padding all lists to MAX_SEQ_LENGTH\n",
        "train['input_ids'] = train['input_ids'].apply(lambda x: x + (max_seq_len - len(x))*[0])\n",
        "train['attention_mask'] = train['attention_mask'].apply(lambda x: x + (max_seq_len - len(x))*[0])\n",
        "train['token_type_ids'] = train['token_type_ids'].apply(lambda x: x + (max_seq_len - len(x))*[0])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Chd5EN1xsPIF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "1dbef82c-0b6d-4481-f507-db7aaeb11471"
      },
      "source": [
        "# visualize data\n",
        "train"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attention_mask</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>label</th>\n",
              "      <th>token_type_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[101, 2054, 2079, 2017, 2228, 2055, 1996, 3976...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[101, 2054, 2079, 2017, 2228, 2055, 1996, 6671...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[101, 2054, 2079, 2017, 2228, 2055, 1996, 2236...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[101, 2054, 2079, 2017, 2228, 2055, 1996, 3808...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[101, 2054, 2079, 2017, 2228, 2055, 1996, 3976...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15003</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[101, 2054, 2079, 2017, 2228, 2055, 1996, 3808...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15004</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[101, 2054, 2079, 2017, 2228, 2055, 1996, 3976...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15005</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[101, 2054, 2079, 2017, 2228, 2055, 1996, 6671...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15006</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[101, 2054, 2079, 2017, 2228, 2055, 1996, 2236...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15007</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[101, 2054, 2079, 2017, 2228, 2055, 1996, 3808...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15008 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          attention_mask  ...                                     token_type_ids\n",
              "0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...\n",
              "1      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              "2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...\n",
              "3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...\n",
              "4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...\n",
              "...                                                  ...  ...                                                ...\n",
              "15003  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...\n",
              "15004  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...\n",
              "15005  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              "15006  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...\n",
              "15007  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...\n",
              "\n",
              "[15008 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_jgOd7Q-hh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize empty dataframe\n",
        "val = pd.DataFrame()\n",
        "\n",
        "# iterate each row in previously loaded train_data\n",
        "# tokenizer(sent_a, sent_b) returns a dictionary of encoded values namely input_ids, attention_mask, token_type_ids\n",
        "# input_ids - IDs returned by bert-tokenizer\n",
        "# attention_mask - 1's for all the ids in the sentence and 0's for all padded tokens\n",
        "# token_type_ids - 0's for all tokens in sent_a, 1's for all tokens in sent_b\n",
        "for i, row in val_data.iterrows():\n",
        "  d = {}\n",
        "  encoded = tokenizer(row['ques'], row['ans'])\n",
        "  d['input_ids'] = encoded['input_ids']\n",
        "  d['attention_mask'] = encoded['attention_mask']\n",
        "  d['token_type_ids'] = encoded['token_type_ids']\n",
        "  d['label'] = sent2idx[row['sentiment']]\n",
        "  val = val.append(d, ignore_index=True)\n",
        "\n",
        "# padding all lists to MAX_SEQ_LENGTH\n",
        "val['input_ids'] = val['input_ids'].apply(lambda x: x + (max_seq_len - len(x))*[0])\n",
        "val['attention_mask'] = val['attention_mask'].apply(lambda x: x + (max_seq_len - len(x))*[0])\n",
        "val['token_type_ids'] = val['token_type_ids'].apply(lambda x: x + (max_seq_len - len(x))*[0])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RZQn1rouly2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "696e02f9-234d-4369-88fb-c6b5647d4810"
      },
      "source": [
        "# visualize data\n",
        "val"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attention_mask</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>label</th>\n",
              "      <th>token_type_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[101, 2054, 2079, 2017, 2228, 2055, 1996, 6671...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[101, 2054, 2079, 2017, 2228, 2055, 1996, 3808...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[101, 2054, 2079, 2017, 2228, 2055, 1996, 2236...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[101, 2054, 2079, 2017, 2228, 2055, 1996, 3976...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[101, 2054, 2079, 2017, 2228, 2055, 1996, 6671...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3745</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[101, 2054, 2079, 2017, 2228, 2055, 1996, 3976...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3746</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[101, 2054, 2079, 2017, 2228, 2055, 1996, 2236...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3747</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[101, 2054, 2079, 2017, 2228, 2055, 1996, 6671...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3748</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[101, 2054, 2079, 2017, 2228, 2055, 1996, 3808...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3749</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[101, 2054, 2079, 2017, 2228, 2055, 1996, 3976...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3750 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         attention_mask  ...                                     token_type_ids\n",
              "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...\n",
              "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...\n",
              "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...\n",
              "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              "...                                                 ...  ...                                                ...\n",
              "3745  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...\n",
              "3746  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...\n",
              "3747  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              "3748  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...\n",
              "3749  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...\n",
              "\n",
              "[3750 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwyK7r-Og5n7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import torch utilities to loading data\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.data.sampler import RandomSampler"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouBDlK6ijqb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert all lists to pytorch tensors\n",
        "input_ids = torch.tensor([r for r in train['input_ids']], dtype=torch.long)\n",
        "attention_mask = torch.tensor([r for r in train['attention_mask']], dtype=torch.long)\n",
        "token_type_ids = torch.tensor([r for r in train['token_type_ids']], dtype=torch.long)\n",
        "label_ids = torch.tensor([r for r in train['label']], dtype=torch.long)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYCJ4fv8j9Vr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wraping tensors into TensorDataset\n",
        "# Initializing RandomSampler for train data \n",
        "# Initialing DataLoader for efficiently loading data\n",
        "train_dataset = TensorDataset(input_ids, attention_mask, token_type_ids, label_ids)\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB9snmHSGy8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert all lists to pytorch tensors\n",
        "input_ids = torch.tensor([r for r in val['input_ids']], dtype=torch.long)\n",
        "attention_mask = torch.tensor([r for r in val['attention_mask']], dtype=torch.long)\n",
        "token_type_ids = torch.tensor([r for r in val['token_type_ids']], dtype=torch.long)\n",
        "label_ids = torch.tensor([r for r in val['label']], dtype=torch.long)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8nJoUrQkZ2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wraping tensors into TensorDataset\n",
        "# Initialing DataLoader for efficiently loading data\n",
        "val_dataset = TensorDataset(input_ids, attention_mask, token_type_ids, label_ids)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMCg3_kR5Mg1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ce21e80-b641-4f1f-bf1b-3cc07f2c4f9f"
      },
      "source": [
        "# define model - BertForSequenceClassification\n",
        "# using bert-base-uncased\n",
        "model_class, pretrained_weights = (\n",
        "    optimus.BertForSequenceClassification,\n",
        "    \"bert-base-uncased\",\n",
        ")\n",
        "\n",
        "# loading pre-trained bert model\n",
        "model = model_class.from_pretrained(pretrained_weights, num_labels=3)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "039bfaa98c0b45aaaf1b69e4072df73a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdde8e3ae18442fda27d8bb3cc70385e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3nInvy8lv-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load model to device\n",
        "model = model.to(device)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ-uuUi7lxBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_parameters = [\n",
        "      {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
        "      {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
        "      ]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55EeaheBbJ4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing optimizer for weight updates\n",
        "# Initializing scheduler for updating learning rate\n",
        "optimizer = optimus.AdamW(optimizer_parameters, lr=lr, correct_bias=False)\n",
        "scheduler = optimus.get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF6_krm1Msca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adding seed values for reproducibility\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z00BzNJNHPIH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64db1186-1560-427a-84d2-e962fadb559f"
      },
      "source": [
        "# placeholder for train-val stats\n",
        "training_stats = []\n",
        "\n",
        "total_t0 = time.time()\n",
        "\n",
        "# Interate through all epochs\n",
        "for epoch_i in range(0, epochs):\n",
        "    ## TRAINING\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    # re-initialize train loss for each epoch\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # convert model to train mode\n",
        "    model.train()\n",
        "\n",
        "    # Iterate for all batches in the dataloader\n",
        "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
        "\n",
        "        # print stats after every 100 steps\n",
        "        if step % 100 == 0 and not step == 0:\n",
        "            elapsed = str(datetime.timedelta(seconds=int(round(time.time() - t0))))\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # un-pack vales in the batch\n",
        "        input_ids, input_mask, segment_ids, label_ids = batch\n",
        "\n",
        "        # push inputs to device\n",
        "        input_ids = input_ids.to(device)\n",
        "        input_mask = input_mask.to(device)\n",
        "        segment_ids = segment_ids.to(device)\n",
        "        label_ids = label_ids.to(device)\n",
        "\n",
        "        # remove any previously computed gradients\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # forward pass of the network\n",
        "        loss, _ = model(input_ids=input_ids,\n",
        "                        attention_mask=input_mask,\n",
        "                        token_type_ids=segment_ids,\n",
        "                        labels=label_ids)\n",
        "\n",
        "        # update loss\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # back-propogation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    # calculate stats for each epoch\n",
        "    avg_train_loss = total_train_loss / (len(train_dataloader) * train_dataloader.batch_size)    \n",
        "    \n",
        "    training_time = str(datetime.timedelta(seconds=int(round(time.time() - t0))))\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    ## VALIDATION\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # convert model to eval mode\n",
        "    model.eval()\n",
        "\n",
        "    # initialize placeholders\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "\n",
        "    # iterate for all batched in the dataloader\n",
        "    for step, batch in enumerate(tqdm(val_dataloader)):\n",
        "        # unpack values in the batch\n",
        "        input_ids, input_mask, segment_ids, label_ids = batch\n",
        "\n",
        "        # load tensors to device\n",
        "        input_ids = input_ids.to(device)\n",
        "        input_mask = input_mask.to(device)\n",
        "        segment_ids = segment_ids.to(device)\n",
        "        label_ids = label_ids.to(device)\n",
        "        \n",
        "        # perform forward pass without tracking gradients\n",
        "        with torch.no_grad():        \n",
        "            loss, logits = model(input_ids=input_ids,\n",
        "                        attention_mask=input_mask,\n",
        "                        token_type_ids=segment_ids,\n",
        "                        labels=label_ids)\n",
        "        # update loss\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Output of the model is the scores for 3 classes namely None, Positive, and Negative\n",
        "        # Computing softmax for finding max probablity\n",
        "        logits = F.softmax(logits, dim=-1)\n",
        "        # move ground truths and predictions to cpu\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = label_ids.to('cpu').numpy()\n",
        "        # get index of max probability\n",
        "        outputs = np.argmax(logits, axis=1)\n",
        "\n",
        "        # comapre ground truths and predictions\n",
        "        total_eval_accuracy += np.sum(outputs == label_ids)        \n",
        "\n",
        "    # compute validation stats\n",
        "    avg_val_accuracy = total_eval_accuracy / (len(val_dataloader) * val_dataloader.batch_size)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    avg_val_loss = total_eval_loss / (len(val_dataloader) * val_dataloader.batch_size)\n",
        "    \n",
        "    validation_time = str(datetime.timedelta(seconds=int(round(time.time() - t0))))\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # add stats to placeholder\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(str(datetime.timedelta(seconds=int(round(time.time() - total_t0))))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 5 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 21%|██▏       | 100/469 [02:17<08:40,  1.41s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of    469.    Elapsed: 0:02:17.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 126/469 [02:53<08:06,  1.42s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BDQmQKLMtpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## INFERENCE\n",
        "\n",
        "def load_test_data(input_dir):\n",
        "  \"\"\"\n",
        "  Load input test data\n",
        "\n",
        "  Arguments:\n",
        "  input_dir {str} - path to data dir\n",
        "\n",
        "  Returns:\n",
        "  df {DataFrame} - loaded data in data frame\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(input_dir + \"test-QA.csv\", sep=\"\\t\", names=['id', 'ques', 'ans', 'sentiment'])\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSuWustPabcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load test data\n",
        "test_data = load_test_data('QA_pairs/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2IIRUTwMIB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# index to label mapping\n",
        "idx2sentiment = {\n",
        "    0: \"None\",\n",
        "    1: \"Positive\",\n",
        "    2: \"Negative\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcx4yXFcMcrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_aspects = ['price',\n",
        "               'shopping',\n",
        "               'transit-location', \n",
        "               'safety',\n",
        "               'nightlife',\n",
        "               'live',\n",
        "               'multiculture',\n",
        "               'green-nature',\n",
        "               'touristy',\n",
        "               'quiet',\n",
        "               'dining',\n",
        "               'general']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdzGi4kP4nyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grouping all the text on 'id'\n",
        "test_grouped_by_id = test_data.groupby(['id'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1XbQS9D60PQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert model to eval mode\n",
        "model.eval()\n",
        "\n",
        "final_preds = pd.DataFrame()\n",
        "test_accuracy = 0\n",
        "\n",
        "l = 0\n",
        "# Iterate all groups in the dataframe groupby\n",
        "for id, group in tqdm(test_grouped_by_id):\n",
        "\n",
        "  test = pd.DataFrame()\n",
        "  # encode all the rows with BERT tokenizer\n",
        "  for i, row in group.iterrows():\n",
        "    d = {}\n",
        "    encoded = tokenizer(row['ques'], row['ans'])\n",
        "    d['input_ids'] = encoded['input_ids']\n",
        "    d['attention_mask'] = encoded['attention_mask']\n",
        "    d['token_type_ids'] = encoded['token_type_ids']\n",
        "    d['label'] = sent2idx[row['sentiment']]\n",
        "    test = test.append(d, ignore_index=True)\n",
        "\n",
        "  # pad all inputs to MAX_SEQ_LENGTH\n",
        "  test['input_ids'] = test['input_ids'].apply(lambda x: x + (max_seq_len - len(x))*[0])\n",
        "  test['attention_mask'] = test['attention_mask'].apply(lambda x: x + (max_seq_len - len(x))*[0])\n",
        "  test['token_type_ids'] = test['token_type_ids'].apply(lambda x: x + (max_seq_len - len(x))*[0])\n",
        "\n",
        "  # convert input lists to tensors\n",
        "  input_ids = torch.tensor([r for r in test['input_ids']], dtype=torch.long)\n",
        "  attention_mask = torch.tensor([r for r in test['attention_mask']], dtype=torch.long)\n",
        "  token_type_ids = torch.tensor([r for r in test['token_type_ids']], dtype=torch.long)\n",
        "  label_ids = torch.tensor([r for r in test['label']], dtype=torch.long)\n",
        "\n",
        "  # push tensors to device\n",
        "  input_ids = input_ids.to(device)\n",
        "  attention_mask = attention_mask.to(device)\n",
        "  token_type_ids = token_type_ids.to(device)\n",
        "  label_ids = label_ids.to(device)\n",
        "\n",
        "  # compute forward pass without tracking gradients\n",
        "  with torch.no_grad():        \n",
        "    loss, logits = model(input_ids=input_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        token_type_ids=token_type_ids,\n",
        "                        labels=label_ids)\n",
        "\n",
        "  # compute softmax on the outputs\n",
        "  logits = F.softmax(logits, dim=-1)\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = label_ids.to('cpu').numpy()\n",
        "  outputs = np.argmax(logits, axis=1)\n",
        "\n",
        "  # evaluate predictions\n",
        "  test_accuracy += np.sum(outputs == label_ids)\n",
        "  l += len(group)\n",
        "\n",
        "  test['pred'] = outputs\n",
        "\n",
        "  # write predictions to dataframe\n",
        "  res = [idx for idx, val in enumerate(outputs) if val != 0]\n",
        "  for val in res:\n",
        "    d = {}\n",
        "    d['id'] = id\n",
        "    d['text'] = group.iloc[val]['ans']\n",
        "    d['aspect'] = group.iloc[val]['ques'].split(' ')[6]\n",
        "    d['sentiment'] = idx2sentiment[outputs[val]]\n",
        "    d['target'] = 'LOCATION1' if 'LOCATION1' in group.iloc[val]['ans'] else 'LOCATION2'\n",
        "    final_preds = final_preds.append(d, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jng8xIhQnY0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print test accuracy\n",
        "test_accuracy / l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEaPRllzdrTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write predictions to csv file\n",
        "final_preds.to_csv('prediction.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW0r1hLL4uSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check deive and usage\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjIF3H6Ody5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}